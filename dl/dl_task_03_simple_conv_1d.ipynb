{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1alxwZ_071FSxbrsp6t6GgZfDJHBp8c-W","timestamp":1716270103923}],"gpuType":"T4","authorship_tag":"ABX9TyOFsNwFGGiE3xfUB8Gg/dRM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## [Problem 1] Creating a one-dimensional convolutional layer class that limits the number of channels to one"],"metadata":{"id":"urgml8GghGWx"}},{"cell_type":"code","source":["import numpy as np\n","import math\n","from keras.datasets import mnist\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"y7p_s9CxhC3w","executionInfo":{"status":"ok","timestamp":1716344859484,"user_tz":-480,"elapsed":4191,"user":{"displayName":"Batgerel M","userId":"12820710479957792879"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Activation functions\n","class Sigmoid:\n","    def forward(self, A):\n","        self.A = A\n","        return self.sigmoid(A)\n","    def backward(self, dZ):\n","        _sig = self.sigmoid(self.A)\n","        return dZ * (1 - _sig)*_sig\n","    def sigmoid(self, X):\n","        return 1 / (1 + np.exp(-X))\n","\n","class Tanh:\n","    def forward(self, A):\n","        self.A = A\n","        return np.tanh(A)\n","    def backward(self, dZ):\n","        return dZ * (1 - (np.tanh(self.A))**2)\n","\n","class Softmax:\n","    def forward(self, X):\n","        self.Z = np.exp(X) / np.sum(np.exp(X), axis=1).reshape(-1,1)\n","        return self.Z\n","    def backward(self, Y):\n","        self.loss = self.loss_func(Y)\n","        return self.Z - Y\n","    def loss_func(self, Y, Z=None):\n","        if Z is None:\n","            Z = self.Z\n","        return (-1)*np.average(np.sum(Y*np.log(Z), axis=1))\n","\n","class ReLU:\n","    def forward(self, A):\n","        self.A = A\n","        return np.clip(A, 0, None)\n","    def backward(self, dZ):\n","        return dZ * np.clip(np.sign(self.A), 0, None)\n","\n","# FC = Neural network\n","class FC:\n","    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer, dropout_rate=0.5):\n","        self.optimizer = optimizer\n","        self.W = initializer.W(n_nodes1, n_nodes2)\n","        self.B = initializer.B(n_nodes2)\n","        self.W_feedback = 0\n","        self.B_feedback = 0\n","        self.dZ = 0\n","        self.dA = 0\n","        self.dropout_rate = dropout_rate\n","        self.mask = None\n","        self.input_X_forward = 0\n","\n","    def forward(self, X):\n","        self.input_X_forward = X\n","        A = np.dot(X, self.W) + self.B\n","\n","        return A\n","\n","    def backward(self, dA):\n","\n","        dW = np.dot(self.input_X_forward.T, dA)\n","        dZ = np.dot(dA, self.W.T)\n","        self.dA = dA\n","        self.dW = dW\n","        self.dZ = dZ\n","\n","        self.W_feedback = self.dW / self.dA.shape[0]\n","        self.B_feedback = np.average(self.dA, axis=0)\n","\n","        self = self.optimizer.update(self)\n","        return dZ\n","\n","    def dropout_forward(self, X, flag):\n","        if flag:\n","            self.mask = np.random.rand(*X.shape) > self.dropout_rate\n","            return X * self.mask\n","        else:\n","            return X * (1.0 - self.dropout_rate)\n","\n","    def dropout_backward(self, X):\n","        return X * self.mask\n","\n","\n","# Defining a Weight Initialization Class\n","class XavierInitializer:\n","    def W(self, n_nodes1, n_nodes2):\n","        self.sigma = math.sqrt(1 / n_nodes1)\n","        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n","        return W\n","    def B(self, n_nodes2):\n","        B = self.sigma * np.random.randn(n_nodes2)\n","        return B\n","\n","class HeInitializer():\n","    def W(self, n_nodes1, n_nodes2):\n","        self.sigma = math.sqrt(2 / n_nodes1)\n","        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n","        return W\n","    def B(self, n_nodes2):\n","        B = self.sigma * np.random.randn(n_nodes2)\n","        return B\n","\n","class SimpleInitializer:\n","    def __init__(self, sigma):\n","        self.sigma = sigma\n","    def W(self, *shape):\n","        W = self.sigma * np.random.randn(*shape)\n","        return W\n","    def B(self, *shape):\n","        B = self.sigma * np.random.randn(*shape)\n","        return B\n","\n","class SimpleInitializerConv1d:\n","    def __init__(self, sigma):\n","        self.sigma = sigma\n","    def W(self, *shape):\n","        W = self.sigma * np.random.randn(*shape)\n","        return W\n","    def B(self, *shape):\n","        B = self.sigma * np.random.randn(*shape)\n","        return B\n","\n","# Defining Gradient Update Class\n","class SGD:\n","    def __init__(self, lr):\n","        self.lr = lr\n","    def update(self, layer):\n","        layer.B = layer.B - self.lr * layer.B_feedback\n","        layer.W = layer.W - self.lr * layer.W_feedback\n","\n","        return layer\n","\n","class AdaGrad:\n","    def __init__(self, lr):\n","        self.lr = lr\n","        self.HW = 1\n","        self.HB = 1\n","    def update(self, layer):\n","        self.HW += layer.dW**2\n","        self.HB += layer.dB**2\n","        layer.W -= self.lr * np.sqrt(1/self.HW) * layer.dW\n","        layer.B -= self.lr * np.sqrt(1/self.HB) * layer.dB\n","\n","# Defining a mini-batch generation iterator\n","class GetMiniBatch:\n","    def __init__(self, X, y, batch_size = 20, seed=0):\n","        self.batch_size = batch_size\n","        np.random.seed(seed)\n","        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n","        self._X = X[shuffle_index]\n","        self._y = y[shuffle_index]\n","        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int64)\n","    def __len__(self):\n","        return self._stop\n","    def __getitem__(self,item):\n","        p0 = item*self.batch_size\n","        p1 = item*self.batch_size + self.batch_size\n","        return self._X[p0:p1], self._y[p0:p1]\n","    def __iter__(self):\n","        self._counter = 0\n","        return self\n","    def __next__(self):\n","        if self._counter >= self._stop:\n","            raise StopIteration()\n","        p0 = self._counter*self.batch_size\n","        p1 = self._counter*self.batch_size + self.batch_size\n","        self._counter += 1\n","        return self._X[p0:p1], self._y[p0:p1]"],"metadata":{"id":"67exQRhGhM9p","executionInfo":{"status":"ok","timestamp":1716346280803,"user_tz":-480,"elapsed":1042,"user":{"displayName":"Batgerel M","userId":"12820710479957792879"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["class SimpleConv1d():\n","\n","    def __init__(self, n_input_hight, f_w, f_b, optimizer):\n","        DIM = 1\n","\n","        self.optimizer = optimizer\n","        # 初期化\n","        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n","        self.f_hight = len(f_w)\n","        self.n_input_hight = n_input_hight\n","        #self.n_input_width = n_input_width\n","        self.W = f_w[:, np.newaxis]\n","        self.B = f_b[:, np.newaxis]\n","        self.dZ = 0\n","        self.dA = 0\n","        self.dB = 0\n","        print(\"N_input:{} F_hight:{}\".format(self.n_input_hight, self.f_hight))\n","        self.n_output_hight = self.n_input_hight - self.f_hight + 1\n","        #self.n_output_width = self.n_input_width - f_width +1\n","        self.input_X_forward = 0\n","        self.output_X_forward = np.zeros([self.n_output_hight, DIM])\n","        self.W_feedback = np.zeros([self.f_hight, DIM])\n","        self.B_feedback = 0\n","        self.Z_feedback = np.zeros([self.n_input_hight, DIM])\n","\n","    def forward(self, X):\n","\n","        self.input_X_forward = X\n","        for h in range(self.n_output_hight):\n","            h1 = h\n","            h2 = h + self.f_hight\n","\n","            X_seg = X[h1:h2]\n","            self.output_X_forward[h] = np.dot(X_seg, self.W) + self.B\n","\n","        return self.output_X_forward\n","\n","    def backward(self, dA):\n","\n","        dA = dA[:,np.newaxis]\n","        for i in range(self.f_hight):\n","            X_seg = self.input_X_forward[i : (i + self.n_output_hight)]\n","            X_seg = X_seg[:,np.newaxis]\n","            self.W_feedback[i] = np.dot(X_seg.T, dA)\n","\n","\n","        self.B_feedback = np.sum(dA, axis=0)\n","\n","        dA_padding = np.zeros([self.f_hight-1, 1])\n","        dA = np.concatenate((dA, dA_padding), axis=0)\n","        dA = np.concatenate((dA_padding, dA), axis=0)\n","        for h in range(self.n_input_hight):\n","            h1 = h\n","            h2 = h + self.f_hight\n","            dA_seg = dA[h1:h2]\n","\n","            dA_seg = np.fliplr(dA_seg.T).T\n","            self.Z_feedback[h] = np.dot(dA_seg.T, self.W)\n","\n","\n","        self = self.optimizer.update(self)\n","        return self.Z_feedback"],"metadata":{"id":"wrygxTk6xqYN","executionInfo":{"status":"ok","timestamp":1716346198007,"user_tz":-480,"elapsed":1293,"user":{"displayName":"Batgerel M","userId":"12820710479957792879"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["## [Problem 2] Output size calculation after one-dimensional convolution"],"metadata":{"id":"8zHqon4QhXW5"}},{"cell_type":"code","source":["def output_size_calculation( n_in, filter_size, padding=0, stride=1):\n","  \"\"\"\n","  Calculate output size after 1d convolution\n","\n","  Parameters\n","  -----------------\n","  n_in: Input size\n","  F: filter size\n","  P: padding number\n","  S: stride number\n","\n","  Return\n","  -----------------\n","  n_out: size of output\n","  \"\"\"\n","  n_out = int((n_in + 2*padding - filter_size) / stride + 1)\n","  return n_out\n","\n","a = output_size_calculation(4,3,0,1)\n","print(\"output:\", a)"],"metadata":{"id":"U9rNRlhlhWsU","executionInfo":{"status":"ok","timestamp":1716346199802,"user_tz":-480,"elapsed":7,"user":{"displayName":"Batgerel M","userId":"12820710479957792879"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"98fe7940-4b2c-422a-de0d-bb4246e7568a"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["output: 2\n"]}]},{"cell_type":"markdown","source":["## [Problem 3] Experiment of one-dimensional convolutional layer with small array"],"metadata":{"id":"H9F_LCjFhpB6"}},{"cell_type":"code","source":["x = np.array([1,2,3,4])\n","w = np.array([3, 5, 7])\n","b = np.array([1])\n","\n","#initializer = SimpleInitializer()\n","optimizer = SGD(0.001)\n","\n","scv = SimpleConv1d(len(x), w, b, optimizer)\n","\n","scv.forward(x)\n","\n","delta_a = np.array([10, 20])\n","\n","scv.backward(delta_a)\n","\n","print(\"delta_b:\",scv.B_feedback)\n","print(\"delta_w:\",scv.W_feedback)\n","print(\"delta_x:\",scv.Z_feedback)\n","\n","delta_b = np.array([30])\n","delta_w = np.array([50, 80, 110])\n","delta_x = np.array([30, 110, 170, 140])\n","\n","print(delta_b)\n","print(delta_w)\n","print(delta_x)"],"metadata":{"id":"7QRGa86hhoOn","executionInfo":{"status":"ok","timestamp":1716346394667,"user_tz":-480,"elapsed":556,"user":{"displayName":"Batgerel M","userId":"12820710479957792879"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1cb31d16-5079-4657-ad85-60088216db60"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["N_input:4 F_hight:3\n","delta_b: [30]\n","delta_w: [[ 50.]\n"," [ 80.]\n"," [110.]]\n","delta_x: [[ 30.]\n"," [110.]\n"," [170.]\n"," [140.]]\n","[30]\n","[ 50  80 110]\n","[ 30 110 170 140]\n"]}]},{"cell_type":"markdown","source":["## [Problem 4] Creating a one-dimensional convolutional layer class that does not limit the number of channels"],"metadata":{"id":"jDwnEGeIh1w0"}},{"cell_type":"code","source":["class Conv1d():\n","\n","    def __init__(self, n_input_hight, f_w, f_b, initializer, optimizer):\n","        self.optimizer = optimizer\n","\n","        self.n_input_hight = n_input_hight\n","        self.W = f_w    #(n_output, n_ch, f_size)\n","        self.B = f_b    #(1, n_ch, n_output)\n","        self.n_output = self.W.shape[0]\n","        self.n_input_ch = self.W.shape[1]\n","        self.f_hight = f_w.shape[2]\n","        self.n_output_hight = self.n_input_hight - self.f_hight + 1\n","        self.input_X_forward = 0\n","        self.output_X_forward = np.zeros((self.W.shape[0], self.n_output_hight))\n","        self.W_feedback = np.zeros_like(self.W)\n","        self.B_feedback = np.zeros_like(self.B)\n","        self.Z_feedback = 0\n","\n","    def forward(self, X):\n","\n","        self.input_X_forward = X\n","        batch_size = self.input_X_forward.shape[0]\n","        A = np.zeros((batch_size, self.n_output, self.n_input_ch, self.n_output_hight))\n","        B = self.B[0]\n","        B = B.T\n","        B = B[np.newaxis]\n","        X = X[:,np.newaxis]\n","        for h in range(self.n_output_hight):\n","            h1 = h\n","            h2 = h + self.f_hight\n","            X_seg = X[:,:,:,h1:h2]\n","            tmp = np.sum(X_seg * self.W, axis=3)\n","            tmp = tmp + B\n","            A[:,:,:,h] = tmp\n","\n","        A = np.sum(A, axis=2)\n","        return A\n","\n","    def backward(self, dA):\n","\n","        batch_size = self.input_X_forward.shape[0]\n","        X = np.tile(self.input_X_forward, (dA.shape[1] ,1))\n","        dL = np.zeros((dA.shape[0], X.shape[1], dA.shape[2]))\n","        for i in range(self.n_output):\n","            o1 = i\n","            o2 = i + self.n_input_ch\n","            tmp = dA[:,i][:,np.newaxis,:]\n","            dL[:,o1:o2] = np.tile(tmp, (self.n_input_ch ,1))\n","\n","        loop = self.n_input_hight - self.n_output_hight + 1\n","        dW_tmp = np.zeros((batch_size, self.n_output, loop))\n","        for i in range(loop):\n","            i1 = i\n","            i2 = i + self.n_output_hight\n","            dX_seg = X[:,:, i1:i2]\n","            dW_tmp[:,:,i] = np.sum(dL * dX_seg, axis=2)\n","\n","        dW_tmp2 = np.average(dW_tmp, axis=0)\n","        for i in range(dW_tmp2.shape[0]):\n","            o1 = i\n","            o2 = i + self.n_input_ch\n","            self.W_feedback[i] = dW_tmp2[o1:o2]\n","\n","\n","        dB = np.sum(dA, axis=2)\n","        dB = np.average(dB, axis=0)\n","        for i in range(self.B.shape[1]):\n","            self.B_feedback[:,i] = dB\n","\n","        self.Z_feedback = np.zeros_like(self.input_X_forward)\n","        for i in range(self.n_output):\n","            dA_padding = np.zeros([batch_size, 1, self.f_hight-1])\n","            dA_tmp = dA[:,i][:,np.newaxis,:]\n","            #print(\"dA_tmp.shape1:\",dA_tmp.shape)\n","            dA_tmp = np.concatenate((dA_tmp, dA_padding), axis=2)\n","            dA_tmp = np.concatenate((dA_padding, dA_tmp), axis=2)\n","            #print(\"dA_tmp.shape2:\",dA_tmp.shape)\n","            dA_tmp = np.tile(dA_tmp, (self.n_input_ch ,1))\n","            dZ_seg = np.zeros_like(self.Z_feedback)\n","\n","            for h in range(self.n_input_hight):\n","                h1 = h\n","                h2 = h + self.f_hight\n","                dA_seg = dA_tmp[:,:,h1:h2]\n","                dA_seg = np.fliplr(dA_seg.T).T\n","                dZ_seg[:,:,h] = np.sum(dA_seg * self.W[i], axis=2)\n","\n","            self.Z_feedback += dZ_seg\n","\n","        self = self.optimizer.update(self)\n","        return self.Z_feedback"],"metadata":{"id":"C_OBp-DIDrw2","executionInfo":{"status":"ok","timestamp":1716346435426,"user_tz":-480,"elapsed":753,"user":{"displayName":"Batgerel M","userId":"12820710479957792879"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["## [Problem 8] Learning and estimation"],"metadata":{"id":"OwwDEDv27Jd5"}},{"cell_type":"code","source":["default_dnn_design = {\n","    'learning_rate':0.001,\n","    'total_layer':3,\n","    'func_layer1':'tanh',\n","    'func_layer2':'tanh',\n","    'func_layer3':'softmax',\n","    'node_layer0':786,\n","    'node_layer1':400,\n","    'node_layer2':200,\n","    'node_layer3':10,\n","    'initializer':'SimpleInitializer',\n","    'initializer_sigma':0.05,\n","    'optimizer':'SGD',\n","}\n","\n","class ScratchCNNClassifier():\n","\n","\n","    def __init__(self, n_epoch, batch_size, verbose = False):\n","        self.verbose = verbose\n","        self.batch_size = batch_size\n","        self.n_epoch = n_epoch\n","        self.loss = 0\n","        self.loss_val = 0\n","        self.activation_func = 0\n","        self.affine_func = 0\n","        self.n_layer = 0\n","        self.layer_instance = [0 for _ in range(64)]\n","\n","\n","    def _crossentropy(self, y_pred, y):\n","\n","        INF_AVOIDANCE = 1e-8\n","        cross_entropy = -1 * y * np.log(y_pred + INF_AVOIDANCE)\n","        return np.sum(cross_entropy, axis=1)\n","\n","    def add_layer(self, model):\n","        self.layer_instance[self.n_layer] = model\n","        self.n_layer += 1\n","        return\n","\n","    def delet_all_layer(self):\n","        self.layer_instance[0:self.n_layer] = 0\n","        self.n_layer = 0\n","\n","        return\n","\n","    def fit(self, X, y, X_val=None, y_val=None):\n","        self.loss = [[0 for i in range(X.shape[0])] for j in range(self.n_epoch)]\n","        self.loss_val = [[0 for i in range(X.shape[0])] for j in range(self.n_epoch)]\n","\n","        i = 0\n","        get_mini_batch = GetMiniBatch(x_train, y_train, self.batch_size)\n","        for epoch in range(self.n_epoch):\n","            loop_count = 0\n","            sum_loss = 0\n","            for mini_X_train, mini_y_train in get_mini_batch:\n","                X = mini_X_train\n","                #Forwardの計算\n","                for layer in range(self.n_layer):\n","                    X = self.layer_instance[layer].forward(X)\n","\n","\n","                sum_loss += self._crossentropy(X, mini_y_train)\n","\n","\n","                dz = mini_y_train\n","                for layer in reversed(range(0, self.n_layer)):\n","                    dz = self.layer_instance[layer].backward(dz)\n","\n","                loop_count += 1\n","\n","            self.loss[i] = sum_loss / loop_count\n","            if X_val is not None and y_val is not None:\n","                y_val_pred = self._predict(X_val)\n","                self.loss_val[i] = self._crossentropy(y_val_pred, y_val)\n","\n","            if self.verbose:\n","                print(\"Epoch:{} Loss:{} Loss(val):{}\".format(i, self.loss[i], self.loss_val[i]))\n","\n","            i +=1\n","\n","        return\n","\n","    def predict(self, X):\n","\n","        for layer in range(self.n_layer):\n","            X = self.layer_instance[layer].forward(X)\n","\n","        max_val = np.max(X, axis=1)\n","        mask = np.ones_like(X)\n","        X[X == max_val[:,np.newaxis]] = 1\n","        X[X != mask] = 0\n","\n","        return X\n","\n","    def _predict(self, X):\n","        #Forwardの計算\n","        for layer in range(self.n_layer):\n","            X = self.layer_instance[layer].forward(X)\n","\n","        return X"],"metadata":{"id":"fz_END8UhzS8","executionInfo":{"status":"ok","timestamp":1716346439953,"user_tz":-480,"elapsed":2,"user":{"displayName":"Batgerel M","userId":"12820710479957792879"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["class Flatten():\n","\n","    def __init__(self):\n","        self.input_X_shape = 0\n","\n","    def forward(self, X):\n","        \"\"\"\n","        X.shape (batch_size, n_input, n_feature1)\n","\n","        return (batch_size, n_input * n_feature)\n","        \"\"\"\n","        self.inout_X_shape = X.shape\n","        output = X.reshape([self.inout_X_shape[0], self.inout_X_shape[1] * self.inout_X_shape[2]])\n","        return output\n","\n","    def backward(self, X):\n","        output = X.reshape(self.inout_X_shape)\n","        return output"],"metadata":{"id":"Oc79QuZzJnmf","executionInfo":{"status":"ok","timestamp":1716346514054,"user_tz":-480,"elapsed":1111,"user":{"displayName":"Batgerel M","userId":"12820710479957792879"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","x_train = x_train.reshape(-1, 784)\n","x_test = x_test.reshape(-1, 784)\n","\n","\n","x_train = x_train.astype(np.float32)\n","x_test = x_test.astype(np.float32)\n","x_train /= 255\n","x_test /= 255\n","\n","enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n","y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n","y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n","\n","\n","x_train = x_train[:,np.newaxis,:]\n","x_test = x_test[:,np.newaxis,:]\n","\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train_one_hot, test_size=0.95)\n","print(x_train.shape)\n","print(x_val.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-nNk9JCWCP-7","executionInfo":{"status":"ok","timestamp":1716346493704,"user_tz":-480,"elapsed":1289,"user":{"displayName":"Batgerel M","userId":"12820710479957792879"}},"outputId":"a72590cf-653b-43b9-ab50-d2569f8c7400"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["(3000, 1, 784)\n","(57000, 1, 784)\n"]}]},{"cell_type":"code","source":["CNN = ScratchCNNClassifier(1, 1)"],"metadata":{"id":"8C1qfutxisZN","executionInfo":{"status":"ok","timestamp":1716346545365,"user_tz":-480,"elapsed":533,"user":{"displayName":"Batgerel M","userId":"12820710479957792879"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["f_w = np.ones((3,1,28))\n","f_b = np.array([[[1,1,1]]])\n","\n","optimizer = SGD(0.01)\n","initializer = XavierInitializer()"],"metadata":{"id":"u2IT6pQA2XeN","executionInfo":{"status":"ok","timestamp":1716346549699,"user_tz":-480,"elapsed":7,"user":{"displayName":"Batgerel M","userId":"12820710479957792879"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["CNN.add_layer(Conv1d(x_train.shape[2], f_w, f_b, initializer, optimizer))\n","CNN.add_layer(Flatten())\n","CNN.add_layer(FC(f_w.shape[0] * (x_train.shape[2] - f_w.shape[2] + 1), 100, initializer, optimizer))\n","CNN.add_layer(Sigmoid())\n","CNN.add_layer(FC(100, 10, initializer, optimizer))\n","CNN.add_layer(Softmax())"],"metadata":{"id":"QpTtIoskKBGl","executionInfo":{"status":"ok","timestamp":1716346590194,"user_tz":-480,"elapsed":574,"user":{"displayName":"Batgerel M","userId":"12820710479957792879"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["CNN.fit(x_train, y_train, x_val, y_val)"],"metadata":{"id":"hV-_3-ZKKCUe","executionInfo":{"status":"ok","timestamp":1716346779005,"user_tz":-480,"elapsed":181438,"user":{"displayName":"Batgerel M","userId":"12820710479957792879"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["y_pred = CNN.predict(x_val)"],"metadata":{"id":"W3s5s-leKyK9","executionInfo":{"status":"ok","timestamp":1716346852815,"user_tz":-480,"elapsed":26985,"user":{"displayName":"Batgerel M","userId":"12820710479957792879"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["print(\"Pred=\\n\", y_pred)\n","print(\"Yval=\\n\", y_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eFz8pdeePhhI","executionInfo":{"status":"ok","timestamp":1716346856959,"user_tz":-480,"elapsed":819,"user":{"displayName":"Batgerel M","userId":"12820710479957792879"}},"outputId":"b3d8a9e0-b29b-46a3-adb6-ebd3f021be56"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Pred=\n"," [[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 1.]\n"," [0. 0. 0. ... 0. 0. 1.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 1.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n","Yval=\n"," [[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 1.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n"]}]},{"cell_type":"code","source":["print(\"Accuracy score={:.3f}\".format(accuracy_score(y_pred, y_val)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sfiWCth_PqAU","executionInfo":{"status":"ok","timestamp":1716346872222,"user_tz":-480,"elapsed":830,"user":{"displayName":"Batgerel M","userId":"12820710479957792879"}},"outputId":"d2222fa7-1297-475a-82a3-8e46c9a8429f"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy score=0.297\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"nQZsQwNGPzGP"},"execution_count":null,"outputs":[]}]}