{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37b28d26-0be7-41f3-aaf8-c171a7799399",
   "metadata": {},
   "source": [
    "## [Problem 1] Simple Forward propagation implementation of RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b94664-6d5d-496d-b64a-0aa29c44d361",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return self.sigmoid(A)\n",
    "    def backward(self, dZ):\n",
    "        _sig = self.sigmoid(self.A)\n",
    "        return dZ * (1 - _sig)*_sig\n",
    "    def sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "\n",
    "class Tanh:\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return np.tanh(A)\n",
    "    def backward(self, dZ):\n",
    "        return dZ * (1 - (np.tanh(self.A))**2)\n",
    "\n",
    "class Softmax:\n",
    "    def forward(self, X):\n",
    "        self.Z = np.exp(X) / np.sum(np.exp(X), axis=1).reshape(-1,1)\n",
    "        return self.Z\n",
    "    def backward(self, Y):\n",
    "        self.loss = self.loss_func(Y)\n",
    "        return self.Z - Y\n",
    "    def loss_func(self, Y, Z=None):\n",
    "        if Z is None:\n",
    "            Z = self.Z\n",
    "        return (-1)*np.average(np.sum(Y*np.log(Z), axis=1))\n",
    "\n",
    "class ReLU:\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return np.clip(A, 0, None)\n",
    "    def backward(self, dZ):\n",
    "        return dZ * np.clip(np.sign(self.A), 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b66a359d-65dc-4ec7-99e0-cd53dbfb4d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma = 0.01):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "\n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B\n",
    "\n",
    "class SGD:\n",
    "\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "\n",
    "        layer.B = layer.B - self.lr * np.average(layer.dA, axis=0)\n",
    "        layer.W = layer.W - self.lr * layer.dW / layer.dA.shape[0]\n",
    "\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c944b72e-5b09-47b8-b8ec-9bf709ace978",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN:\n",
    "\n",
    "    def __init__(self, W_x, B_x, W_h, initializer, optimizer, activation):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        #self.W1 = initializer.W(n_wx_nodes1, n_wx_nodes2)\n",
    "        #self.B1 = initializer.B(1)\n",
    "        self.Wx = W_x\n",
    "        self.Bx = B_x\n",
    "        self.Wh = W_h\n",
    "        self.dA = 0\n",
    "        self.dW = 0\n",
    "        self.W = 0\n",
    "        self.B = 0\n",
    "        self.input_X_forward = 0\n",
    "        self.input_prev_ht_forward = 0\n",
    "        self.activation = activation\n",
    "        self.n_sequece = 0\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        self.input_X_forward = X\n",
    "        self.n_sequece = X.shape[1]\n",
    "        tmp_prev_h = np.zeros((X.shape[1]+1, X.shape[0], self.Wx.shape[1]))\n",
    "        self.input_prev_ht_forward = np.zeros((X.shape[0], X.shape[1], self.Wx.shape[1]))\n",
    "        y = np.zeros((X.shape[0], X.shape[1], self.Wx.shape[1]))\n",
    "        tmp_y = np.zeros((X.shape[1], X.shape[0], self.Wx.shape[1]))\n",
    "        for i in range(self.n_sequece):\n",
    "            Xt = X[:,i]\n",
    "            #Xt:(batch, Feature)\n",
    "            tmp = np.dot(Xt, self.Wx) + self.Bx + tmp_prev_h[i]\n",
    "            #tmp:(batch, Node1)\n",
    "            tmp_y[i] = self.activation.forward(tmp)\n",
    "            #h_prev:(batch, node2)\n",
    "            tmp_prev_h[i+1] = np.dot(tmp_y[i], self.Wh)\n",
    "\n",
    "        self.input_prev_ht_forward = tmp_prev_h.transpose(1,0,2)\n",
    "        y = tmp_y.transpose(1,0,2)\n",
    "        return y\n",
    "\n",
    "    def backward(self, dA):\n",
    "\n",
    "        dz = np.zeros_like(self.input_X_forward)\n",
    "        tmp_dz = dz.transpose(1,0,2)\n",
    "\n",
    "        loss_h = np.zeros((dA.shape[0], dA.shape[1]+1, dA.shape[2]))\n",
    "        for i in reversed(range(self.n_sequece)):\n",
    "            loss = dA[:,i,:] + loss_h[:,i,:]\n",
    "            loss = self.activation.backward(loss) * loss\n",
    "            dW = np.dot(self.input_X_forward[:,i,:].T, loss)\n",
    "            tmp_dz[i] = np.dot(loss, self.Wx.T)\n",
    "            self.dA = loss\n",
    "            self.dW = dW\n",
    "            self.W = self.Wx\n",
    "            self.B = self.Bx\n",
    "            self = self.optimizer.update(self)\n",
    "            self.Wx = self.W\n",
    "            self.Bx = self.B\n",
    "\n",
    "            loss_h[:,i+1,:] = np.dot(loss, self.Wh.T)\n",
    "            self.dA = loss\n",
    "            dW = np.dot(self.input_prev_ht_forward[:,i,:].T, loss)\n",
    "            self.dW = dW\n",
    "            self.W = self.Wh\n",
    "            self.B = 0\n",
    "            self = self.optimizer.update(self)\n",
    "            self.Wh = self.W\n",
    "\n",
    "        dz = tmp_dz.transpose(1,0,2)\n",
    "        return dz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a9b569-15dc-4f3b-af74-e11f1899b45a",
   "metadata": {},
   "source": [
    "## [Problem 2] Experiment of forward propagation with small sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c90a24-2bfe-424a-aefe-92583bed7ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "x = np.array([[[1, 2], [2, 3], [3, 4]]])/100\n",
    "w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100\n",
    "w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100\n",
    "batch_size = x.shape[0] # 1\n",
    "n_sequences = x.shape[1] # 3\n",
    "n_features = x.shape[2] # 2\n",
    "n_nodes = w_x.shape[1] # 4\n",
    "h = np.zeros((batch_size, n_nodes))\n",
    "b = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "079bab2d-9e15-4a17-a5cc-127ad732a997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.76188798, 0.76213958, 0.76239095, 0.76255841],\n",
       "        [0.792209  , 0.8141834 , 0.83404912, 0.84977719],\n",
       "        [0.79494228, 0.81839002, 0.83939649, 0.85584174]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = SimpleRNN(w_x, 1, w_h, initializer=SimpleInitializer(), optimizer=SGD(0.01), activation=Tanh())\n",
    "\n",
    "answer = rnn.forward(x)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d474e8d7-33bb-4dd4-be1f-b18421c56e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79494228, 0.81839002, 0.83939649, 0.85584174])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[0,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7309ec23-1ce3-4f1f-a424-4a057a6f9aae",
   "metadata": {},
   "source": [
    "## [Problem 3] (Advance assignment) Implementation of backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a3131d1-2d7d-421e-b1cd-fde6922dc46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dA = np.array([[[0.01, 0.02, 0.03, 0.04], [0.01, 0.02, 0.03, 0.04], [0.01, 0.02, 0.03, 0.04]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "babd5f6b-18b0-4f1b-9f86-0b7e175321fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4.75883037e-05, 6.05642872e-05],\n",
       "        [4.75883582e-05, 6.05643690e-05],\n",
       "        [4.75884400e-05, 6.05644781e-05]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.backward(dA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6089216c-4b05-40cd-88b3-bfdc250278aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
